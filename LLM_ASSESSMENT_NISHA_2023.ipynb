{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOwI4JUP0S77W4IBpuUGYqt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "77614e9ed9934c3da45d8f9313144016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbb1114038244c2c92a7c6ec5febba99",
              "IPY_MODEL_7606e20350c24c71a420d5cef35e61a9",
              "IPY_MODEL_0f9f9de5bef84a6c9a18825ae463ee74"
            ],
            "layout": "IPY_MODEL_a90a514c11b24abf93c3f50881248a84"
          }
        },
        "fbb1114038244c2c92a7c6ec5febba99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f409980461a400b8ddadb107e65126f",
            "placeholder": "​",
            "style": "IPY_MODEL_73ac1c8377f44d71a23265b6bd1342a2",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "7606e20350c24c71a420d5cef35e61a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9361a89caa8847dfaa645119bb79700f",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f294f5065b6346faa632c9470754e3be",
            "value": 548105171
          }
        },
        "0f9f9de5bef84a6c9a18825ae463ee74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ef321c578d144f89105e29d920d2a33",
            "placeholder": "​",
            "style": "IPY_MODEL_0981608d5a71409d9a89d031242c4cee",
            "value": " 548M/548M [00:05&lt;00:00, 183MB/s]"
          }
        },
        "a90a514c11b24abf93c3f50881248a84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f409980461a400b8ddadb107e65126f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73ac1c8377f44d71a23265b6bd1342a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9361a89caa8847dfaa645119bb79700f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f294f5065b6346faa632c9470754e3be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ef321c578d144f89105e29d920d2a33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0981608d5a71409d9a89d031242c4cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b538b90fe6de4847bd43093e6194630f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82c8e7e15ed64ed4a57dd4cb8a89319a",
              "IPY_MODEL_f89292fdd475448fb9c296443b76995f",
              "IPY_MODEL_0309ca7058294ac986b1fc4dc658ee7f"
            ],
            "layout": "IPY_MODEL_3b594709cf834a7880440583ffe2a6d8"
          }
        },
        "82c8e7e15ed64ed4a57dd4cb8a89319a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c0d51213e2349b3abe1a1d197ab67ec",
            "placeholder": "​",
            "style": "IPY_MODEL_3c4a392d1f2d49e5a1013c472d84098d",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "f89292fdd475448fb9c296443b76995f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dddb1368458439f95cd4180b0fb7f03",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a4dab7badd84046a1527b42cf04862b",
            "value": 124
          }
        },
        "0309ca7058294ac986b1fc4dc658ee7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb9448073ac041a9b68b29667fe8829a",
            "placeholder": "​",
            "style": "IPY_MODEL_d541d74fd3264f8da7ee41b9bf0dc1e4",
            "value": " 124/124 [00:00&lt;00:00, 6.56kB/s]"
          }
        },
        "3b594709cf834a7880440583ffe2a6d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c0d51213e2349b3abe1a1d197ab67ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c4a392d1f2d49e5a1013c472d84098d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0dddb1368458439f95cd4180b0fb7f03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a4dab7badd84046a1527b42cf04862b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb9448073ac041a9b68b29667fe8829a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d541d74fd3264f8da7ee41b9bf0dc1e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nisha1365/LLM_AI-Planet-Bootcamp/blob/main/LLM_ASSESSMENT_NISHA_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question-1:\n",
        "\n",
        "Use Transformers model and build a Code Generation application on the given data.\n",
        "Data: https://huggingface.co/datasets/theblackcat102/evol-codealpaca-v1"
      ],
      "metadata": {
        "id": "EBewTHVY0fcN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install Required Libraries:**\n",
        "\n",
        "\n",
        "You'll need to install the necessary libraries, including the Transformers library from Hugging Face."
      ],
      "metadata": {
        "id": "j6XnEtNj0uTu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMmiirBgw-8H",
        "outputId": "5f43b691-d508-44e1-cab4-43e828295b79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the Dataset:**\n",
        "\n",
        "You can use the datasets library to load your dataset from the provided link."
      ],
      "metadata": {
        "id": "mB4cvxlo00Cm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import datasets\n",
        "\n",
        "# Load the dataset from the Hugging Face Datasets Hub\n",
        "dataset = datasets.load_dataset(\"theblackcat102/evol-codealpaca-v1\")\n",
        "\n",
        "# Load a pre-trained GPT-2 model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "# Function to generate code from instructions at a specific index\n",
        "def generate_code_from_index(index):\n",
        "    # Get the instruction and output at the specified index\n",
        "    instruction = dataset[\"train\"][index][\"instruction\"]\n",
        "    actual_code = dataset[\"train\"][index][\"output\"]\n",
        "\n",
        "    # Tokenize the instruction\n",
        "    input_ids = tokenizer.encode(instruction, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate code\n",
        "    generated_output = model.generate(input_ids, max_length=100, num_return_sequences=1)\n",
        "\n",
        "    # Decode the generated code\n",
        "    generated_code = tokenizer.decode(generated_output[0], skip_special_tokens=True)\n",
        "\n",
        "    return instruction, generated_code, actual_code\n",
        "\n",
        "# Specify the index of the instruction you want to generate code for\n",
        "instruction_index = 0  # Change this to the desired index\n",
        "\n",
        "# Generate code for the specified index\n",
        "instruction, generated_code, actual_code = generate_code_from_index(instruction_index)\n",
        "\n",
        "# Print the results\n",
        "print(\"Instructions:\")\n",
        "print(instruction)\n",
        "print(\"Generated Code:\")\n",
        "print(generated_code)\n",
        "print(\"Actual Code:\")\n",
        "print(actual_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "77614e9ed9934c3da45d8f9313144016",
            "fbb1114038244c2c92a7c6ec5febba99",
            "7606e20350c24c71a420d5cef35e61a9",
            "0f9f9de5bef84a6c9a18825ae463ee74",
            "a90a514c11b24abf93c3f50881248a84",
            "6f409980461a400b8ddadb107e65126f",
            "73ac1c8377f44d71a23265b6bd1342a2",
            "9361a89caa8847dfaa645119bb79700f",
            "f294f5065b6346faa632c9470754e3be",
            "0ef321c578d144f89105e29d920d2a33",
            "0981608d5a71409d9a89d031242c4cee",
            "b538b90fe6de4847bd43093e6194630f",
            "82c8e7e15ed64ed4a57dd4cb8a89319a",
            "f89292fdd475448fb9c296443b76995f",
            "0309ca7058294ac986b1fc4dc658ee7f",
            "3b594709cf834a7880440583ffe2a6d8",
            "3c0d51213e2349b3abe1a1d197ab67ec",
            "3c4a392d1f2d49e5a1013c472d84098d",
            "0dddb1368458439f95cd4180b0fb7f03",
            "9a4dab7badd84046a1527b42cf04862b",
            "eb9448073ac041a9b68b29667fe8829a",
            "d541d74fd3264f8da7ee41b9bf0dc1e4"
          ]
        },
        "id": "Bwv5PJeUzlko",
        "outputId": "166d5b1c-2488-4c98-f70e-4377f9fbed4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77614e9ed9934c3da45d8f9313144016"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b538b90fe6de4847bd43093e6194630f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 169, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instructions:\n",
            "Please amend the subsequent Python script so that it includes a 'while' loop rather than the existing 'for' loop, which iterates through the items of an integer list.\n",
            "\n",
            "The script currently has a bug where it attempts to print an object that is outside the bounds of the list. Fix this error and modify the script to use 'while' instead of 'for' loop. Ensure your script correctly handles empty lists. \n",
            "\n",
            "```python\n",
            "  # Establish an integer list\n",
            "  arr = [1, 2, 3, 4]\n",
            "\n",
            "  # Determine the length of the list\n",
            "  n = len(arr)\n",
            "\n",
            "  # Traverse the list and output each individual element\n",
            "  for i in range(n+1):\n",
            "      print(arr[i])\n",
            "```\n",
            "Generated Code:\n",
            "Please amend the subsequent Python script so that it includes a 'while' loop rather than the existing 'for' loop, which iterates through the items of an integer list.\n",
            "\n",
            "The script currently has a bug where it attempts to print an object that is outside the bounds of the list. Fix this error and modify the script to use 'while' instead of 'for' loop. Ensure your script correctly handles empty lists. \n",
            "\n",
            "```python\n",
            "  # Establish an integer list\n",
            "  arr = [1, 2, 3, 4]\n",
            "\n",
            "  # Determine the length of the list\n",
            "  n = len(arr)\n",
            "\n",
            "  # Traverse the list and output each individual element\n",
            "  for i in range(n+1):\n",
            "      print(arr[i])\n",
            "```\n",
            "\n",
            "Actual Code:\n",
            "```python\n",
            "# Establish an integer list\n",
            "arr = [1, 2, 3, 4]\n",
            "\n",
            "# Determine the length of the list\n",
            "n = len(arr)\n",
            "\n",
            "# Initialize index at 0\n",
            "i = 0\n",
            "\n",
            "# Traverse the list and output each individual element\n",
            "while i < n:\n",
            "    print(arr[i])\n",
            "    i += 1\n",
            "```\n",
            "In the given code, it tries to access `arr[n]` which is out of bounds as python list indexing starts from 0 and ends at n-1 for a list of length n.\n",
            "Also, I used `while` loop as per your request. By initializing `i=0` before the loop and `i += 1` within the loop, we can iterate over the list. This iteration continues until `i` is less than `n`, the length of the list. The `while` loop will not proceed if the list is empty so it correctly handles empty lists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PROMPT - 2**"
      ],
      "metadata": {
        "id": "JPi8ASNT06RF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the index of the instruction you want to generate code for\n",
        "instruction_index = 2  # Change this to the desired index\n",
        "\n",
        "# Generate code for the specified index\n",
        "instruction, generated_code, actual_code = generate_code_from_index(instruction_index)\n",
        "\n",
        "# Print the results\n",
        "print(\"Instructions:\")\n",
        "print(instruction)\n",
        "print(\"Generated Code:\")\n",
        "print(generated_code)\n",
        "print(\"Actual Code:\")\n",
        "print(actual_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJS9U1g1z6oI",
        "outputId": "d2b00650-6a9b-4720-b5a8-a0ada0d0a1bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instructions:\n",
            "Create a recursive function in Java that predicts the next four elements in the Fibonacci Sequence after a given index, without using any loops or storing previous Fibonnaci sequence values in an array.\n",
            "Generated Code:\n",
            "Create a recursive function in Java that predicts the next four elements in the Fibonacci Sequence after a given index, without using any loops or storing previous Fibonnaci sequence values in an array.\n",
            "\n",
            "The following example shows how to use the Fibonacci Sequence to predict the next four elements in the Fibonacci Sequence after a given index.\n",
            "\n",
            "public static final String FibonacciSequence = new StringBuilder(); public static final String FibonacciSequence.Add(String\n",
            "Actual Code:\n",
            "You can achieve this using a combination of recursion for calculating the fibonacci numbers and dynamic programming for efficiency purpose (we use a HashMap to store outer level fibonacci calculations). Below is the Java code;\n",
            "\n",
            "```java\n",
            "import java.util.HashMap;\n",
            "\n",
            "public class Main {\n",
            "    static HashMap<Integer, Integer> cache = new HashMap<>();\n",
            "    \n",
            "    public static void main(String args[]) {\n",
            "        int index = 10; // Starting index\n",
            "        for(int i=1; i<=4; i++){\n",
            "            System.out.println(fibonacci(index+i));\n",
            "        }\n",
            "    }\n",
            "    \n",
            "    static int fibonacci(int n){\n",
            "        if (n<0){\n",
            "            throw new IllegalArgumentException(\"n cannot be less than zero\");\n",
            "        }\n",
            "        if(n<=2){\n",
            "            return n;\n",
            "        }\n",
            "        //Use cache to store outer level fibonacci calculations to reduce duplicate calculations\n",
            "        if(cache.containsKey(n)){\n",
            "            return cache.get(n);\n",
            "        }\n",
            "        int fibValue = fibonacci(n-1) + fibonacci(n-2);\n",
            "        cache.put(n, fibValue);\n",
            "        return fibValue;\n",
            "    }\n",
            "}\n",
            "```\n",
            "\n",
            "In the above code, replace `index` with the given index after which you want the next four Fibonacci numbers. This code will work for the first 46 Fibonacci numbers (starting index at 0). For larger values, you would need to use `BigInteger` instead of `int`. Please note that the very first index of the Fibonacci series is considered as 0 in the above solution.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PROMPT-3**"
      ],
      "metadata": {
        "id": "kHd7kpsz0_zd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the index of the instruction you want to generate code for\n",
        "instruction_index = 3  # Change this to the desired index\n",
        "\n",
        "# Generate code for the specified index\n",
        "instruction, generated_code, actual_code = generate_code_from_index(instruction_index)\n",
        "\n",
        "# Print the results\n",
        "print(\"Instructions:\")\n",
        "print(instruction)\n",
        "print(\"Generated Code:\")\n",
        "print(generated_code)\n",
        "print(\"Actual Code:\")\n",
        "print(actual_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy1JFgx10J0f",
        "outputId": "d775a6ba-0b71-424f-e155-baba651e1d22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 221, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instructions:\n",
            "Develop a program that uses natural language processing (NLP) techniques to classify sentences from different documents based on their intention or sentiment. \n",
            "\n",
            "In the simple example below, you have only one sentence and the outcome is straightforward:\n",
            "\n",
            "sentence = \"I want to buy a car\"\n",
            "\n",
            "For the more complex task, you will classify multiple sentences from different documents. You may need to extract the sentences from the documents and then process them. The program should be able to handle a variety of intentions i.e., enquiry, purchase, negative feedback, and positive feedback. It should also be able to provide a confidence level for each categorized intention.\n",
            "\n",
            "In addition, evaluate the performance of your program using suitable metrics and write a brief report of your findings. Include any challenges you encountered and how you mitigate them. \n",
            "\n",
            "You may use any NLP libraries or tools of your choice. \n",
            "\n",
            "Consider aspects such as tokenization, stop word removal, lemmatization, vectorization, etc. for pre-processing the data. Please handle sentences in different languages.\n",
            "Generated Code:\n",
            "Develop a program that uses natural language processing (NLP) techniques to classify sentences from different documents based on their intention or sentiment. \n",
            "\n",
            "In the simple example below, you have only one sentence and the outcome is straightforward:\n",
            "\n",
            "sentence = \"I want to buy a car\"\n",
            "\n",
            "For the more complex task, you will classify multiple sentences from different documents. You may need to extract the sentences from the documents and then process them. The program should be able to handle a variety of intentions i.e., enquiry, purchase, negative feedback, and positive feedback. It should also be able to provide a confidence level for each categorized intention.\n",
            "\n",
            "In addition, evaluate the performance of your program using suitable metrics and write a brief report of your findings. Include any challenges you encountered and how you mitigate them. \n",
            "\n",
            "You may use any NLP libraries or tools of your choice. \n",
            "\n",
            "Consider aspects such as tokenization, stop word removal, lemmatization, vectorization, etc. for pre-processing the data. Please handle sentences in different languages. \n",
            "Actual Code:\n",
            "This task requires writing of a significant volume of code, which is not fully suitable for a text-based medium. However, I will outline a general solution using Python and scikit-learn. We'll use \"CountVectorizer\" for bag-of-words model and \"TfidVectorizer\" for TF-IDF. To handle different languages, we can use 'langdetect' library.\n",
            "\n",
            "1. Import required libraries\n",
            "```python\n",
            "import pandas as pd\n",
            "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.naive_bayes import MultinomialNB\n",
            "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
            "from langdetect import detect\n",
            "from nltk.corpus import stopwords\n",
            "from nltk.stem import WordNetLemmatizer\n",
            "from nltk.tokenize import word_tokenize\n",
            "import nltk\n",
            "nltk.download('punkt')\n",
            "nltk.download('wordnet')\n",
            "nltk.download('stopwords')\n",
            "```\n",
            "\n",
            "2. Load sentence data and labels. For example, if data is stored in a csv format:\n",
            "```python\n",
            "data = pd.read_csv('path_to_data')\n",
            "```\n",
            "\n",
            "3. Pre-process data (remove stop words, lemmatization, tokenization):\n",
            "```python\n",
            "def preprocess_text(text):\n",
            "    stop_words = set(stopwords.words('english')) \n",
            "    lemmatizer = WordNetLemmatizer()\n",
            "    word_tokens = word_tokenize(text) \n",
            "    filtered_sentence = [lemmatizer.lemmatize(w) for w in word_tokens if w not in stop_words]\n",
            "    return ' '.join(filtered_sentence)\n",
            "\n",
            "data['processed_sentence'] = data['sentence'].apply(preprocess_text)\n",
            "```\n",
            "\n",
            "4. Vectorization (Bag of words model / TF-IDF):\n",
            "```python\n",
            "vectorizer = CountVectorizer() # or use TfidfVectorizer()\n",
            "X = vectorizer.fit_transform(data['processed_sentence'])\n",
            "```\n",
            "\n",
            "5. Split data into train and test data:\n",
            "```python\n",
            "X_train, X_test, y_train, y_test = train_test_split(X, data['label'], test_size=0.2, random_state=42)\n",
            "```\n",
            "\n",
            "6. Applying Naive Bayes Classifier (or any other suitable classifier):\n",
            "```python\n",
            "clf = MultinomialNB().fit(X_train, y_train)\n",
            "predicted = clf.predict(X_test)\n",
            "```\n",
            "\n",
            "7. Checking classifier performance:\n",
            "```python\n",
            "print(\"Accuracy:\", accuracy_score(y_test, predicted))\n",
            "print(\"Confusion Matrix:\", confusion_matrix(y_test, predicted))\n",
            "print(\"Classification Report:\", classification_report(y_test, predicted))\n",
            "```\n",
            "\n",
            "Challenges:\n",
            "1. Language variation: Implemented language detection to determine the language of each document.\n",
            "2. High dimensionality: Bag of Words model or even TF-IDF model creates an extremely high dimensional feature space which ends up having many zero an many zero entries. We mitigated this using dimensionality reduction techniques, such as PCA.\n",
            "3. Context Sensitivity: NLP analysis can sometimes incorrectly classify contexts, especially with sarcasm or irony. Such instances are hard to handle in absence of contextual knowledge. Training the model with large and context-rich data can improve the performance.\n",
            "4. Use of colloquialism or slangs: These words are often not present in standard language dictionaries. Informal language and misspellings are common in digital communication. We handled it by introducing a spell-check and autocorrect phase, and by using an updated slang dictionary.\n",
            "5. Resource limitation: NLP may need a lot of memory or computing power, especially in the vectorization phase. Sub-sampling or using more efficient hardware can be a solution.\n",
            "\n",
            "Notice: This code snippet doesn't include handling sentences in different languages. We would have to implement language detection for each sentence and subsequently define appropriate stopwords and tokenizers for each language.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question-2:\n",
        "\n",
        "Use GenAI Stack and build an ChatBot application like ChatGPT on your own data\n",
        "You are free to use any default data type(CSV/PDF/JSON)"
      ],
      "metadata": {
        "id": "1vnyQueu1GmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/aiplanethub/genai-stack.git@0.2.0"
      ],
      "metadata": {
        "id": "frnIVKh36JAg",
        "outputId": "1af88114-676e-404a-c3a0-813e591ce800",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/aiplanethub/genai-stack.git@0.2.0\n",
            "  Cloning https://github.com/aiplanethub/genai-stack.git (to revision 0.2.0) to /tmp/pip-req-build-oeqd23kc\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/aiplanethub/genai-stack.git /tmp/pip-req-build-oeqd23kc\n",
            "  Running command git checkout -b 0.2.0 --track origin/0.2.0\n",
            "  Switched to a new branch '0.2.0'\n",
            "  Branch '0.2.0' set up to track remote branch '0.2.0' from 'origin'.\n",
            "  Resolved https://github.com/aiplanethub/genai-stack.git to commit 653122b3633b33f3648f08e5e96febb06eb437cf\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.10/dist-packages (from genai-stack==0.2.1) (8.1.7)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from genai-stack==0.2.1) (2.31.0)\n",
            "Collecting langchain>=0.0.232 (from genai-stack==0.2.1)\n",
            "  Downloading langchain-0.0.306-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-hub (from genai-stack==0.2.1)\n",
            "  Downloading llama_hub-0.0.34-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index (from genai-stack==0.2.1)\n",
            "  Downloading llama_index-0.8.38-py3-none-any.whl (854 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m854.4/854.4 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn==0.23.0 (from genai-stack==0.2.1)\n",
            "  Downloading uvicorn-0.23.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from genai-stack==0.2.1)\n",
            "  Downloading fastapi-0.103.2-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting weaviate-client (from genai-stack==0.2.1)\n",
            "  Downloading weaviate_client-3.24.1-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers (from genai-stack==0.2.1)\n",
            "  Downloading transformers-4.33.3-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gpt4all>=1.0.8 (from genai-stack==0.2.1)\n",
            "  Downloading gpt4all-1.0.12-py3-none-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonschema==4.18.6 (from genai-stack==0.2.1)\n",
            "  Downloading jsonschema-4.18.6-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2==3.1.2 in /usr/local/lib/python3.10/dist-packages (from genai-stack==0.2.1) (3.1.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from genai-stack==0.2.1) (2.0.1+cu118)\n",
            "Collecting chromadb==0.4.5 (from genai-stack==0.2.1)\n",
            "  Downloading chromadb-0.4.5-py3-none-any.whl (402 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.8/402.8 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf==3.14.0 (from genai-stack==0.2.1)\n",
            "  Downloading pypdf-3.14.0-py3-none-any.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.8/269.8 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers==2.2.2 (from genai-stack==0.2.1)\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydantic<2.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.5->genai-stack==0.2.1) (1.10.12)\n",
            "Collecting chroma-hnswlib==0.7.2 (from chromadb==0.4.5->genai-stack==0.2.1)\n",
            "  Downloading chroma-hnswlib-0.7.2.tar.gz (31 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fastapi>=0.95.2 (from genai-stack==0.2.1)\n",
            "  Downloading fastapi-0.99.1-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb==0.4.5->genai-stack==0.2.1)\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.5->genai-stack==0.2.1) (1.23.5)\n",
            "Collecting posthog>=2.4.0 (from chromadb==0.4.5->genai-stack==0.2.1)\n",
            "  Downloading posthog-3.0.2-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.5->genai-stack==0.2.1) (4.5.0)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb==0.4.5->genai-stack==0.2.1)\n",
            "  Downloading pulsar_client-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb==0.4.5->genai-stack==0.2.1)\n",
            "  Downloading onnxruntime-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers>=0.13.2 (from chromadb==0.4.5->genai-stack==0.2.1)\n",
            "  Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypika>=0.48.9 (from chromadb==0.4.5->genai-stack==0.2.1)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.5->genai-stack==0.2.1) (4.66.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb==0.4.5->genai-stack==0.2.1)\n",
            "  Downloading overrides-7.4.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.5->genai-stack==0.2.1) (6.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2==3.1.2->genai-stack==0.2.1) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.18.6->genai-stack==0.2.1) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.18.6->genai-stack==0.2.1) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.18.6->genai-stack==0.2.1) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.18.6->genai-stack==0.2.1) (0.10.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->genai-stack==0.2.1) (0.15.2+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->genai-stack==0.2.1) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->genai-stack==0.2.1) (1.11.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->genai-stack==0.2.1) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers==2.2.2->genai-stack==0.2.1)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence-transformers==2.2.2->genai-stack==0.2.1)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11>=0.8 (from uvicorn==0.23.0->genai-stack==0.2.1)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.28.0,>=0.27.0 (from fastapi>=0.95.2->genai-stack==0.2.1)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.232->genai-stack==0.2.1) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.232->genai-stack==0.2.1) (2.0.20)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.232->genai-stack==0.2.1) (3.8.5)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.232->genai-stack==0.2.1) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.232->genai-stack==0.2.1) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain>=0.0.232->genai-stack==0.2.1)\n",
            "  Downloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain>=0.0.232->genai-stack==0.2.1)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.38 (from langchain>=0.0.232->genai-stack==0.2.1)\n",
            "  Downloading langsmith-0.0.41-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.232->genai-stack==0.2.1) (2.8.5)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.232->genai-stack==0.2.1) (8.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->genai-stack==0.2.1) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->genai-stack==0.2.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->genai-stack==0.2.1) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->genai-stack==0.2.1) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->genai-stack==0.2.1) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->genai-stack==0.2.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->genai-stack==0.2.1) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->genai-stack==0.2.1) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->genai-stack==0.2.1) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->genai-stack==0.2.1) (16.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->genai-stack==0.2.1) (23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->genai-stack==0.2.1) (2023.6.3)\n",
            "Collecting tokenizers>=0.13.2 (from chromadb==0.4.5->genai-stack==0.2.1)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers->genai-stack==0.2.1)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting atlassian-python-api (from llama-hub->genai-stack==0.2.1)\n",
            "  Downloading atlassian_python_api-3.41.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.2/167.2 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting html2text (from llama-hub->genai-stack==0.2.1)\n",
            "  Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from llama-hub->genai-stack==0.2.1) (5.9.5)\n",
            "Collecting retrying (from llama-hub->genai-stack==0.2.1)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Collecting tiktoken (from llama-index->genai-stack==0.2.1)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai>=0.26.4 (from llama-index->genai-stack==0.2.1)\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index->genai-stack==0.2.1) (1.5.3)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.28->genai-stack==0.2.1)\n",
            "  Downloading urllib3-1.26.17-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/143.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index->genai-stack==0.2.1) (2023.6.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index->genai-stack==0.2.1)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from llama-index->genai-stack==0.2.1) (4.11.2)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from llama-index->genai-stack==0.2.1) (1.5.7)\n",
            "Collecting tree-sitter-languages (from llama-index->genai-stack==0.2.1)\n",
            "  Downloading tree_sitter_languages-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting validators<1.0.0,>=0.21.2 (from weaviate-client->genai-stack==0.2.1)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting authlib<2.0.0,>=1.2.1 (from weaviate-client->genai-stack==0.2.1)\n",
            "  Downloading Authlib-1.2.1-py2.py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.232->genai-stack==0.2.1) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.232->genai-stack==0.2.1) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.232->genai-stack==0.2.1) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.232->genai-stack==0.2.1) (1.3.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain>=0.0.232->genai-stack==0.2.1) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain>=0.0.232->genai-stack==0.2.1) (1.1.3)\n",
            "Requirement already satisfied: cryptography>=3.2 in /usr/local/lib/python3.10/dist-packages (from authlib<2.0.0,>=1.2.1->weaviate-client->genai-stack==0.2.1) (41.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain>=0.0.232->genai-stack==0.2.1)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain>=0.0.232->genai-stack==0.2.1)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.4.5->genai-stack==0.2.1)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.5->genai-stack==0.2.1) (23.5.26)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.5->genai-stack==0.2.1) (3.20.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.4.5->genai-stack==0.2.1) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.4.5->genai-stack==0.2.1)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb==0.4.5->genai-stack==0.2.1)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.4.5->genai-stack==0.2.1) (2.8.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain>=0.0.232->genai-stack==0.2.1) (2.0.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index->genai-stack==0.2.1)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "INFO: pip is looking at multiple versions of uvicorn[standard] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting uvicorn[standard]>=0.18.3 (from chromadb==0.4.5->genai-stack==0.2.1)\n",
            "  Downloading uvicorn-0.23.1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn==0.23.0->genai-stack==0.2.1)\n",
            "  Downloading httptools-0.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (428 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.8/428.8 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn==0.23.0->genai-stack==0.2.1)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn==0.23.0->genai-stack==0.2.1)\n",
            "  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn==0.23.0->genai-stack==0.2.1)\n",
            "  Downloading watchfiles-0.20.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn==0.23.0->genai-stack==0.2.1)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecated (from atlassian-python-api->llama-hub->genai-stack==0.2.1)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: oauthlib in /usr/local/lib/python3.10/dist-packages (from atlassian-python-api->llama-hub->genai-stack==0.2.1) (3.2.2)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from atlassian-python-api->llama-hub->genai-stack==0.2.1) (1.3.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->llama-index->genai-stack==0.2.1) (2.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.2->genai-stack==0.2.1) (1.3.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index->genai-stack==0.2.1) (2023.3.post1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==2.2.2->genai-stack==0.2.1) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->genai-stack==0.2.1) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers==2.2.2->genai-stack==0.2.1) (9.4.0)\n",
            "Collecting tree-sitter (from tree-sitter-languages->llama-index->genai-stack==0.2.1)\n",
            "  Downloading tree_sitter-0.20.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (484 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.3/484.3 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.2->authlib<2.0.0,>=1.2.1->weaviate-client->genai-stack==0.2.1) (1.15.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.5->genai-stack==0.2.1)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->atlassian-python-api->llama-hub->genai-stack==0.2.1) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.2->authlib<2.0.0,>=1.2.1->weaviate-client->genai-stack==0.2.1) (2.21)\n",
            "Building wheels for collected packages: genai-stack, sentence-transformers, chroma-hnswlib, pypika\n",
            "  Building wheel for genai-stack (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for genai-stack: filename=genai_stack-0.2.1-py2.py3-none-any.whl size=61056 sha256=633cc575035d855e7f2a0404c9bfbcfb5d4646280146c8386b6260546a6e6c03\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nlu19p8l/wheels/2b/7d/57/140ada527c0612853a2390e2485200bf3dfd353387bd6b997e\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=6081f7261a50ac0dbdca8be4759ae4efa16840190dd31c1823f31b47ebefe528\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "  Building wheel for chroma-hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chroma-hnswlib: filename=chroma_hnswlib-0.7.2-cp310-cp310-linux_x86_64.whl size=2287471 sha256=4f7017c79eb2336c22b841a3087e53f5189c1824b333b411e4993505d3295174\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/2b/0d/ee457f6782f75315bb5828d5c2dc5639d471afbd44a830b9dc\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=aeb02e5c4836baf36de425a0381d396f904f19f46b4530b6bbeebc53085166a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built genai-stack sentence-transformers chroma-hnswlib pypika\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, pypika, monotonic, websockets, validators, uvloop, urllib3, tree-sitter, retrying, python-dotenv, pypdf, pulsar-client, overrides, mypy-extensions, marshmallow, jsonpointer, humanfriendly, httptools, html2text, h11, deprecated, chroma-hnswlib, backoff, watchfiles, uvicorn, typing-inspect, tree-sitter-languages, starlette, jsonpatch, coloredlogs, tiktoken, posthog, openai, onnxruntime, langsmith, jsonschema, huggingface-hub, gpt4all, fastapi, dataclasses-json, authlib, weaviate-client, transformers, langchain, chromadb, atlassian-python-api, llama-index, llama-hub, sentence-transformers, genai-stack\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.4\n",
            "    Uninstalling urllib3-2.0.4:\n",
            "      Successfully uninstalled urllib3-2.0.4\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.19.0\n",
            "    Uninstalling jsonschema-4.19.0:\n",
            "      Successfully uninstalled jsonschema-4.19.0\n",
            "Successfully installed atlassian-python-api-3.41.2 authlib-1.2.1 backoff-2.2.1 chroma-hnswlib-0.7.2 chromadb-0.4.5 coloredlogs-15.0.1 dataclasses-json-0.6.1 deprecated-1.2.14 fastapi-0.99.1 genai-stack-0.2.1 gpt4all-1.0.12 h11-0.14.0 html2text-2020.1.16 httptools-0.6.0 huggingface-hub-0.17.3 humanfriendly-10.0 jsonpatch-1.33 jsonpointer-2.4 jsonschema-4.18.6 langchain-0.0.306 langsmith-0.0.41 llama-hub-0.0.34 llama-index-0.8.38 marshmallow-3.20.1 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.16.0 openai-0.28.1 overrides-7.4.0 posthog-3.0.2 pulsar-client-3.3.0 pypdf-3.14.0 pypika-0.48.9 python-dotenv-1.0.0 retrying-1.3.4 safetensors-0.3.3 sentence-transformers-2.2.2 sentencepiece-0.1.99 starlette-0.27.0 tiktoken-0.5.1 tokenizers-0.13.3 transformers-4.33.3 tree-sitter-0.20.2 tree-sitter-languages-1.7.0 typing-inspect-0.9.0 urllib3-1.26.17 uvicorn-0.23.0 uvloop-0.17.0 validators-0.22.0 watchfiles-0.20.0 weaviate-client-3.24.1 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "86268WuK6WvZ",
        "outputId": "440d54f1-39ba-41bb-d8e9-ae50fc82366a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.4/298.4 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from genai_stack.stack.stack import Stack\n",
        "from genai_stack.etl.langchain import LangchainETL\n",
        "from genai_stack.embedding.langchain import LangchainEmbedding\n",
        "from genai_stack.prompt_engine.engine import PromptEngine\n",
        "from genai_stack.model.gpt3_5 import OpenAIGpt35Model\n",
        "from genai_stack.retriever.langchain import LangChainRetriever\n",
        "from genai_stack.memory.langchain import ConversationBufferMemory\n",
        "from genai_stack.vectordb import ChromaDB"
      ],
      "metadata": {
        "id": "KFIsA3B37uxW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from genai_stack.model import OpenAIGpt35Model\n",
        "\n",
        "model = OpenAIGpt35Model.from_kwargs(\n",
        "    parameters={\"openai_api_key\": \"sk-xxxx\"} # Update with your OpenAI Key\n",
        ")\n",
        "\n",
        "# Create ETL\n",
        "etl = LangchainETL.from_kwargs(\n",
        "    **get_config_from_source_kwargs(\"csv\", \"/content/demographics_event_qual.csv\")\n",
        ")\n",
        "\n",
        "# Connect the ETL, Embedding and Vectordb component using Stack\n",
        "stack = Stack(model=model, embedding=get_default_embeddings(), etl=etl, vectordb=ChromaDB.from_kwargs())\n",
        "\n",
        "etl.run()\n",
        "\n",
        "model.predict(\"what are the column names in the csv file?\")"
      ],
      "metadata": {
        "id": "UQKRTb-f-ICj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}